# -*- coding: utf-8 -*-
"""movie prediciton task 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yoe5Cduxst8PKrSg1BjSH5hv9dRtDKch
"""

!pip install category encoders

import statsmodels.regression.linear_model as smf

import statsmodels.api as sm

import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import cross_val_score, train_test_split

import seaborn as sns

import numpy as np

import pandas as pd

movies_df = pd.read_csv("/content/archive.zip", encoding = 'latin-1')
movies_df.head()

movies_df.info()

movies_df.hist()

rest_df = pd.read_csv('/content/archive.zip', encoding='latin1')

train_df, validation_df = train_test_split(rest_df, train_size = 0.75, random_state = 101)
train_df.head(2)

validation_df.head(2)

test_df = movies_df

test_df[movies_df.duplicated(keep = False)]

movies_df.info()

train_df.info()

train_df.describe()

filled_df = pd.concat([train_df, validation_df], axis = 0)
filled_df.head(2)

filled_df = filled_df.values
train_df = train_df.values
validation_df = validation_df.values

from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge
from sklearn.metrics import r2_score, mean_squared_error

from sklearn.neighbors import KNeighborsRegressor

# Commented out IPython magic to ensure Python compatibility.
import lightgbm as lgb
import matplotlib.pyplot as plt
import os
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import statsmodels.regression.linear_model as smf
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from statsmodels.formula.api import ols

sns.set()
# %matplotlib inline

train_df, validation_df = train_test_split(rest_df, train_size = 0.75, random_state = 101)
train_df.head(2)

test_df[movies_df.duplicated(keep = False)]

movies_df.describe(include = 'all')

train_df.shape

train_missing = list(train_df.isnull().sum())
val_missing = list(validation_df.isnull().sum())
test_misisng = list(test_df.isnull().sum())

train_missing_percent = list(train_df.isnull().sum() / len(train_df) * 100)
val_missing_percent = list(validation_df.isnull().sum() / len(validation_df) * 100)
test_misisng_percent = list(test_df.isnull().sum() / len(test_df) * 100)

sns.displot(movies_df.isnull())
plt.title("Missing values in dataset")
plt.show()

sns.heatmap(movies_df.isnull(), cmap = 'viridis')
plt.title("Missing values in dataset")
plt.show()